#!/bin/bash --login
########## SBATCH Lines for Resource Request ##########
#SBATCH --time=48:00:00             # limit of wall clock time - how long the job will run (same as -t)
#SBATCH --nodes=1                   # number of different nodes - could be an exact number or a range of nodes (same as -N)
#SBATCH --ntasks=1                  # number of tasks - how many tasks (nodes) that you require (same as -n)
#SBATCH --gres=gpu:a100:4
#SBATCH --cpus-per-task=16           # number of CPUs (or cores) per task (same as -c)
#SBATCH --mem-per-cpu=16G            # memory required per allocated CPU (or core) - amount of memory (in bytes)
#SBATCH --job-name run_10          # you can give your job a name for easier identification (same as -J)
#SBATCH -o ./slurm_log/%j.log
########## Command Lines to Run ##########
module load GCC/9.1.0-2.32
cd /mnt/home/kumarab6/project/HoP ### change to the directory where your code is located
conda activate hop2 ### Activate virtual environment
srun ./tools/dist_train.sh configs/hop_bevdet/run_10.py 4 --seed 0
scontrol show job $SLURM_JOB_ID ### write job information to output file

